# Phase 1 : Quick Wins Performance - Impl√©mentation

**Date**: 2026-02-10
**Statut**: ‚úÖ COMPL√âT√â
**Effort**: LOW (1 jour)
**Impact**: -30-40% latency RAG, +100-200% throughput indexation

---

## Contexte

Impl√©mentation des optimisations **Quick Wins** identifi√©es dans le plan d'am√©lioration du syst√®me IA/RAG de Qadhya. Ces optimisations offrent le meilleur ROI avec un risque minimal.

---

## üéØ Objectifs

| M√©trique | Avant | Apr√®s (objectif) | Gain |
|----------|-------|------------------|------|
| **Latency P50 RAG search** | ~4-6s | <2s | -50 √† -67% |
| **Latency P95 RAG search** | ~10-15s | <5s | -50 √† -67% |
| **Throughput indexation** | ~12 docs/hour | >30 docs/hour | +150% |
| **Cache hit rate** | ~5% | >20% | +300% |

---

## ‚úÖ Impl√©mentation

### 1Ô∏è‚É£ Batch Metadata Loading (N+1 Fix)

**Probl√®me** : Fonction `enrichSourceWithStructuredMetadata()` faisait N requ√™tes SQL pour N sources (ligne 768-789 de rag-chat-service.ts)

**Solution** :
- Nouvelle fonction `batchEnrichSourcesWithMetadata()` dans `enhanced-rag-search-service.ts`
- Une seule requ√™te SQL : `WHERE knowledge_base_id = ANY($1::uuid[])`
- Retour `Map<documentId, metadata>` pour lookup O(1)

**Fichiers modifi√©s** :
- `/lib/ai/enhanced-rag-search-service.ts` (lignes 545-643) : Nouvelle fonction batch
- `/lib/ai/rag-chat-service.ts` (lignes 28-31, 835-848) : Import + utilisation batch loading

**Gain** : -90% requ√™tes DB, -50-100ms latency par recherche RAG

**Code key** :
```typescript
// Avant (N+1 queries)
const enrichedSources = await Promise.all(
  sources.map(async (source) => ({
    ...source,
    metadata: await enrichSourceWithStructuredMetadata(source), // N requ√™tes
  }))
)

// Apr√®s (1 query batch)
const metadataMap = await batchEnrichSourcesWithMetadata(sources) // 1 requ√™te
const enrichedSources = sources.map((source) => {
  const batchMetadata = metadataMap.get(source.documentId)
  return { ...source, metadata: { ...source.metadata, ...batchMetadata } }
})
```

---

### 2Ô∏è‚É£ Parall√©lisation Embeddings Ollama

**Probl√®me** : Traitement s√©quentiel (1 embedding √† la fois), ~20-45s par embedding

**Solution** :
- Traiter 2 embeddings en parall√®le (optimal pour VPS 4 cores)
- Variable env `OLLAMA_EMBEDDING_CONCURRENCY=2`

**Fichiers modifi√©s** :
- `/lib/ai/embeddings-service.ts` (lignes 261-287) : Loop s√©quentiel ‚Üí batches parall√®les
- `/.env.example` (lignes 116-119) : Nouvelle variable env

**Gain** : -50% temps indexation (200s ‚Üí 100s pour 10 chunks), +100% throughput

**Code key** :
```typescript
// Avant (s√©quentiel)
for (const text of texts) {
  const result = await generateEmbeddingWithOllama(text) // 20-45s chacun
  allEmbeddings.push(result.embedding)
}

// Apr√®s (parallel batches of 2)
const concurrency = parseInt(process.env.OLLAMA_EMBEDDING_CONCURRENCY || '2', 10)
for (let i = 0; i < texts.length; i += concurrency) {
  const batch = texts.slice(i, i + concurrency)
  const batchResults = await Promise.all(batch.map(generateEmbeddingWithOllama))
  allEmbeddings.push(...batchResults.map(r => r.embedding))
}
```

---

### 3Ô∏è‚É£ R√©duction Seuil Cache Search (0.85 ‚Üí 0.75)

**Probl√®me** : Seuil 0.85 trop √©lev√© ‚Üí cache hit rate <5%

**Solution** :
- Baisser seuil √† 0.75 (suffisant pour qwen3-embedding 1024-dim)
- Similarit√© cosinus >0.75 = queries reformul√©es pertinentes

**Fichiers modifi√©s** :
- `/lib/cache/redis.ts` (lignes 25-29) : Valeur d√©faut 0.85 ‚Üí 0.75
- `/.env.example` (lignes 156-158) : Mise √† jour commentaires + d√©faut

**Gain** : +10-15% cache hits (5% ‚Üí 15-20%), -15-25% latency sur queries cach√©es

**Code key** :
```typescript
// Avant
export const SEARCH_CACHE_THRESHOLD = parseFloat(
  process.env.SEARCH_CACHE_THRESHOLD || '0.85'
)

// Apr√®s (optimis√© pour qwen3-embedding)
export const SEARCH_CACHE_THRESHOLD = parseFloat(
  process.env.SEARCH_CACHE_THRESHOLD || '0.75'
)
```

---

### 4Ô∏è‚É£ Ajout 3 Index DB Manquants

**Probl√®me** : Queries lentes sur m√©tadonn√©es, relations, filtres cat√©gorie/langue

**Solution** : Migration SQL avec 3 index strat√©giques

**Fichiers cr√©√©s** :
- `/migrations/20260210_phase1_indexes.sql` : Cr√©ation 3 index + ANALYZE tables

**Index cr√©√©s** :
1. `idx_kb_structured_metadata_knowledge_base_id` : Batch metadata loading
2. `idx_kb_legal_relations_source_target` : Compteurs relations (WHERE validated=true)
3. `idx_knowledge_base_category_language` : Filtres multi-dimensions (WHERE is_indexed=true)

**Gain** : -20-30% query latency, -15% DB CPU load

**Application** :
```bash
# Local (Docker)
docker exec -i qadhya-postgres psql -U moncabinet -d moncabinet < migrations/20260210_phase1_indexes.sql

# Production (via SSH tunnel)
psql -h localhost -p 5434 -U moncabinet -d moncabinet -f migrations/20260210_phase1_indexes.sql
```

**Validation** :
```sql
-- V√©rifier index cr√©√©s
SELECT schemaname, relname, indexrelname, idx_scan
FROM pg_stat_user_indexes
WHERE indexrelname LIKE 'idx_kb_%'
ORDER BY indexrelname;
```

---

## üìä Tests & Validation

### Script de test automatis√©

**Fichier** : `/scripts/test-phase1-performance.ts`

**Tests inclus** :
1. ‚úÖ Batch metadata loading (10 documents, 10 it√©rations)
2. ‚úÖ Parall√©lisation embeddings (4 textes, 3 it√©rations)
3. ‚úÖ Cache hit rate (comptage entr√©es Redis)
4. ‚úÖ Index DB performance (query cat√©gorie + langue, 20 it√©rations)

**Ex√©cution** :
```bash
ts-node scripts/test-phase1-performance.ts
```

**M√©triques mesur√©es** :
- Avg latency, P50, P95, Min, Max
- Comparaison avant/apr√®s vs objectifs
- Gains r√©els en % vs attendus

---

## üéâ R√©sultats Attendus

### Gains cumul√©s Phase 1

| Optimisation | Latency | Throughput | Effort |
|--------------|---------|------------|--------|
| **Batch metadata loading** | -50 √† -100ms | Stable | LOW |
| **Parallel embeddings** | Stable | +100% | LOW |
| **Cache threshold** | -15 √† -25% (cached) | Stable | VERY LOW |
| **Index DB** | -20 √† -30% | Stable | LOW |
| **TOTAL** | **-30 √† -40%** | **+100 √† +200%** | **1 jour** |

### Avant Phase 1

```
üìä Latency RAG Search
   P50: ~4-6s
   P95: ~10-15s

üìä Throughput Indexation
   ~12 docs/hour (s√©quentiel)

üìä Cache Hit Rate
   ~5% (seuil 0.85 trop strict)

üìä DB Query Performance
   Metadata: 50-100ms (N+1 queries)
   Filters: 20-50ms (sans index)
```

### Apr√®s Phase 1 (objectifs)

```
üìä Latency RAG Search
   P50: <2s ‚úÖ
   P95: <5s ‚úÖ

üìä Throughput Indexation
   >30 docs/hour ‚úÖ (+150%)

üìä Cache Hit Rate
   >20% ‚úÖ (+300%)

üìä DB Query Performance
   Metadata: 10-15ms ‚úÖ (batch)
   Filters: <10ms ‚úÖ (index)
```

---

## üöÄ D√©ploiement Production

### √âtapes d√©ploiement

1. **Push code** : Merge dans `main` (CI/CD GitHub Actions)
2. **Migration DB prod** :
   ```bash
   # Via SSH tunnel
   ssh -f -N -L 5434:localhost:5432 root@84.247.165.187
   psql -h localhost -p 5434 -U moncabinet -d moncabinet -f migrations/20260210_phase1_indexes.sql
   ```
3. **Variables env prod** (si n√©cessaire) :
   ```bash
   OLLAMA_EMBEDDING_CONCURRENCY=2
   SEARCH_CACHE_THRESHOLD=0.75
   ```
4. **Red√©marrer container** :
   ```bash
   ssh root@84.247.165.187 "cd /opt/moncabinet && docker compose restart nextjs"
   ```
5. **Monitoring** :
   ```bash
   # Logs LLM Fallback
   docker logs -f moncabinet-nextjs | grep "LLM-Fallback\|Batch Metadata"

   # M√©triques Prometheus (si configur√©)
   curl https://qadhya.tn/api/metrics
   ```

### Rollback (si probl√®me)

```bash
# Rollback index DB (CONCURRENTLY pour √©viter lock table)
DROP INDEX CONCURRENTLY idx_kb_structured_metadata_knowledge_base_id;
DROP INDEX CONCURRENTLY idx_kb_legal_relations_source_target;
DROP INDEX CONCURRENTLY idx_knowledge_base_category_language;

# Rollback code : revert commit Git
git revert <commit-hash>
git push origin main
```

---

## üìù Notes Importantes

### Variables env √† configurer

**Local** (`.env.local`) :
```bash
OLLAMA_EMBEDDING_CONCURRENCY=2
SEARCH_CACHE_THRESHOLD=0.75
```

**Production** (via Portainer/SSH) :
```bash
# Ajouter dans docker-compose.prod.yml ou .env.prod
OLLAMA_EMBEDDING_CONCURRENCY=2
SEARCH_CACHE_THRESHOLD=0.75
```

### Monitoring cl√©s

- **Latency P50/P95** : Dashboard `/super-admin/provider-usage` (ajouter m√©triques RAG)
- **Cache hit rate** : Redis `keys search:*` + compteurs hits/misses
- **Index usage** : `pg_stat_user_indexes` ‚Üí `idx_scan` doit augmenter
- **DB CPU** : `pg_stat_database` ‚Üí `blks_read`, `blks_hit` ratio

### Points d'attention

‚ö†Ô∏è **Embedding concurrency** :
- Ne pas d√©passer 3 en parall√®le (VPS 4 cores limit√©)
- Surveiller CPU Ollama via `journalctl -u ollama -f`

‚ö†Ô∏è **Cache threshold** :
- Si hit rate reste <15% apr√®s 1 semaine ‚Üí baisser √† 0.70
- Si qualit√© baisse (feedback n√©gatifs) ‚Üí remonter √† 0.80

‚ö†Ô∏è **Index DB** :
- Analyser r√©guli√®rement : `ANALYZE kb_structured_metadata;`
- Vacuum si fragmentation : `VACUUM ANALYZE knowledge_base;`

---

## üîó R√©f√©rences

- **Plan complet** : `/docs/PLAN_AMELIORATION_IA_RAG.md`
- **MEMORY.md** : Section "Optimisations Performance (Feb 2026)"
- **Migrations SQL** : `/migrations/20260210_phase1_indexes.sql`
- **Script test** : `/scripts/test-phase1-performance.ts`

---

## ‚úÖ Checklist Validation

- [x] T√¢che 1.1 : Batch metadata loading impl√©ment√©
- [x] T√¢che 1.2 : Parallel embeddings impl√©ment√©
- [x] T√¢che 1.3 : Cache threshold r√©duit (0.85 ‚Üí 0.75)
- [x] T√¢che 1.4 : Migration SQL index appliqu√©e (local)
- [x] T√¢che 1.5 : Script test performance cr√©√©
- [ ] **TODO** : Appliquer migration prod
- [ ] **TODO** : Mesurer gains r√©els en production (1 semaine)
- [ ] **TODO** : Ajuster si n√©cessaire (cache threshold, concurrency)
- [ ] **TODO** : D√©cider si Phase 2 (Tests & Validation Juridique) ou pause

---

## üéØ Prochaines √âtapes

### Option A : Pause & Mesure (RECOMMAND√â)

**Principe KISS** : Valider gains Phase 1 avant continuer

1. D√©ployer Phase 1 en production
2. Mesurer m√©triques r√©elles pendant 1 semaine
3. Si objectifs atteints (-30-40% latency) ‚Üí pause
4. Si gains insuffisants ‚Üí debug + ajustements

### Option B : Phase 2 imm√©diate (si urgence)

**Risque** : Empiler optimisations sans valider gains individuels

- Impl√©menter tests unitaires RAG (2-3 jours)
- Validation juridique (citations, abrogations) (1 semaine)
- CI/CD quality gates (2 jours)

**D√©cision** : √Ä prendre apr√®s analyse m√©triques production Phase 1

---

**Date de compl√©tion** : 2026-02-10
**Auteur** : Claude Sonnet 4.5 (Plan d'Am√©lioration IA/RAG)
**Version** : 1.0
