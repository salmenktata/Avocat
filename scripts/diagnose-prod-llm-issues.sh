#!/bin/bash
# =============================================================================
# Script de diagnostic des erreurs LLM en production (qadhya.tn)
# =============================================================================
#
# Probl√®me signal√© :
#   - Groq : 401 Invalid API Key
#   - DeepSeek : 401 Authentication Fails
#   - Ollama : mod√®le qwen2.5:3b non disponible (?)
#
# Ce script diagnostique les cl√©s API sur le serveur production
# =============================================================================

set -e

VPS_HOST="root@84.247.165.187"
CONTAINER="moncabinet-nextjs"

echo "==================================================================="
echo "üîç Diagnostic LLM Production - $(date)"
echo "==================================================================="
echo ""

echo "üìä √âtape 1/5 : V√©rification cl√©s API en base de donn√©es production"
echo "-------------------------------------------------------------------"
ssh $VPS_HOST "docker exec moncabinet-postgres psql -U moncabinet -d moncabinet -c \"
SELECT
  provider,
  label,
  is_active,
  last_used_at,
  last_error,
  error_count,
  LEFT(api_key_encrypted, 20) || '...' as key_preview
FROM api_keys
ORDER BY provider;
\""
echo ""

echo "üìä √âtape 2/5 : V√©rification variables d'environnement container"
echo "-------------------------------------------------------------------"
ssh $VPS_HOST "docker exec $CONTAINER sh -c 'echo \"OLLAMA_ENABLED=\$OLLAMA_ENABLED\"'"
ssh $VPS_HOST "docker exec $CONTAINER sh -c 'echo \"OLLAMA_BASE_URL=\$OLLAMA_BASE_URL\"'"
ssh $VPS_HOST "docker exec $CONTAINER sh -c 'echo \"OLLAMA_CHAT_MODEL=\$OLLAMA_CHAT_MODEL\"'"
ssh $VPS_HOST "docker exec $CONTAINER sh -c 'echo \"NODE_ENV=\$NODE_ENV\"'"
echo ""

echo "üìä √âtape 3/5 : Test connectivit√© Ollama depuis container"
echo "-------------------------------------------------------------------"
ssh $VPS_HOST "docker exec $CONTAINER sh -c 'curl -s http://host.docker.internal:11434/api/tags 2>&1 | head -20'"
echo ""

echo "üìä √âtape 4/5 : V√©rification mod√®les Ollama disponibles sur VPS"
echo "-------------------------------------------------------------------"
ssh $VPS_HOST "ollama list"
echo ""

echo "üìä √âtape 5/5 : Logs r√©cents des erreurs LLM"
echo "-------------------------------------------------------------------"
ssh $VPS_HOST "docker logs $CONTAINER --tail 50 | grep -iE '(401|api.key|authentication|LLM-Fallback)' | tail -20"
echo ""

echo "==================================================================="
echo "‚úÖ Diagnostic termin√©"
echo "==================================================================="
echo ""
echo "üìù Actions recommand√©es :"
echo ""
echo "   1. Si cl√©s API manquantes en production :"
echo "      ‚Üí Importer cl√©s : npm run db:import-api-keys (sur VPS)"
echo ""
echo "   2. Si mod√®le Ollama manquant :"
echo "      ‚Üí Pull mod√®le : ssh $VPS_HOST 'ollama pull qwen2.5:3b'"
echo ""
echo "   3. Si erreurs 401 persistent malgr√© cl√©s valides :"
echo "      ‚Üí R√©g√©n√©rer cl√©s API sur les dashboards providers"
echo "      ‚Üí Mettre √† jour en base via scripts/import-api-keys-to-db.ts"
echo ""
