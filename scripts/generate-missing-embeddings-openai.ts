#!/usr/bin/env tsx
/**
 * Script de g√©n√©ration des embeddings manquants avec OpenAI
 *
 * G√©n√®re les embeddings OpenAI pour tous les chunks qui n'en ont pas.
 * Beaucoup plus rapide qu'Ollama (API vs local).
 *
 * Usage :
 *   npx tsx scripts/generate-missing-embeddings-openai.ts [--batch-size=50] [--category=<category>]
 */

import { db } from '@/lib/db/db';
import { sql } from 'drizzle-orm';
import OpenAI from 'openai';

interface ChunkToEmbed {
  id: string;
  knowledge_base_id: string;
  chunk_index: number;
  content: string;
  kb_title: string;
  kb_category: string;
}

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

/**
 * G√©n√®re un embedding OpenAI pour un texte
 */
async function generateOpenAIEmbedding(text: string): Promise<number[] | null> {
  try {
    const response = await openai.embeddings.create({
      model: 'text-embedding-3-small', // 1536 dimensions
      input: text,
      encoding_format: 'float',
    });

    return response.data[0].embedding;
  } catch (error) {
    console.error('Erreur g√©n√©ration embedding:', error);
    return null;
  }
}

/**
 * R√©cup√®re les chunks sans embeddings
 */
async function getChunksWithoutEmbeddings(category?: string): Promise<ChunkToEmbed[]> {
  console.log('üîç R√©cup√©ration des chunks sans embeddings...\n');

  let query = sql`
    SELECT
      kbc.id,
      kbc.knowledge_base_id,
      kbc.chunk_index,
      kbc.content,
      kb.title as kb_title,
      kb.category as kb_category
    FROM knowledge_base_chunks kbc
    INNER JOIN knowledge_base kb ON kbc.knowledge_base_id = kb.id
    WHERE kb.is_active = true
    AND kb.is_indexed = true
    AND kbc.embedding IS NULL
  `;

  if (category) {
    query = sql`${query} AND kb.category = ${category}`;
  }

  query = sql`${query} ORDER BY kb.category, kb.title, kbc.chunk_index`;

  const results = await db.execute(query);
  return results.rows as any as ChunkToEmbed[];
}

/**
 * Met √† jour un chunk avec son embedding
 */
async function updateChunkEmbedding(chunkId: string, embedding: number[]): Promise<void> {
  // Stocker dans embedding_openai (colonne 1536-dim)
  await db.execute(sql`
    UPDATE knowledge_base_chunks
    SET embedding_openai = ${JSON.stringify(embedding)}::vector(1536)
    WHERE id = ${chunkId}
  `);
}

/**
 * Traite un batch de chunks
 */
async function processBatch(
  chunks: ChunkToEmbed[],
  batchIndex: number,
  totalBatches: number
): Promise<{ success: number; failed: number }> {
  let success = 0;
  let failed = 0;

  console.log(`\n${'='.repeat(80)}`);
  console.log(`üì¶ Batch ${batchIndex}/${totalBatches} (${chunks.length} chunks)`);
  console.log('='.repeat(80));

  for (let i = 0; i < chunks.length; i++) {
    const chunk = chunks[i];

    try {
      // G√©n√©rer l'embedding
      const embedding = await generateOpenAIEmbedding(chunk.content);

      if (!embedding) {
        console.log(`   ‚ùå [${i + 1}/${chunks.length}] √âchec g√©n√©ration embedding`);
        failed++;
        continue;
      }

      // Mettre √† jour en DB
      await updateChunkEmbedding(chunk.id, embedding);

      success++;

      // Log progression tous les 10 chunks
      if ((i + 1) % 10 === 0 || i === chunks.length - 1) {
        console.log(`   ‚úÖ [${i + 1}/${chunks.length}] ${chunk.kb_category} | ${chunk.kb_title.substring(0, 40)}`);
      }

      // Petit d√©lai pour √©viter rate limiting (OpenAI: 3000 RPM tier 1)
      await new Promise(resolve => setTimeout(resolve, 20)); // 50 req/s max

    } catch (error) {
      console.error(`   ‚ùå [${i + 1}/${chunks.length}] Erreur:`, error);
      failed++;
    }
  }

  return { success, failed };
}

async function main() {
  const args = process.argv.slice(2);
  const batchSizeArg = args.find(arg => arg.startsWith('--batch-size='));
  const batchSize = batchSizeArg ? parseInt(batchSizeArg.split('=')[1]) : 50;
  const categoryArg = args.find(arg => arg.startsWith('--category='));
  const category = categoryArg ? categoryArg.split('=')[1] : undefined;
  const dryRun = args.includes('--dry-run');

  console.log('üöÄ G√©n√©ration des embeddings manquants avec OpenAI\n');
  console.log(`Configuration:`);
  console.log(`   - Batch size: ${batchSize}`);
  console.log(`   - Cat√©gorie: ${category || 'toutes'}`);
  console.log(`   - Mode: ${dryRun ? 'DRY RUN (simulation)' : 'PRODUCTION'}`);
  console.log(`   - Mod√®le: text-embedding-3-small (1536-dim)`);
  console.log(`   - Rate limit: ~50 req/s (avec d√©lai 20ms)\n`);

  // V√©rifier la cl√© API
  if (!process.env.OPENAI_API_KEY) {
    console.error('‚ùå OPENAI_API_KEY manquante dans .env');
    process.exit(1);
  }

  try {
    // R√©cup√©rer les chunks sans embeddings
    const chunks = await getChunksWithoutEmbeddings(category);

    if (chunks.length === 0) {
      console.log('‚úÖ Aucun chunk sans embedding trouv√© !\n');
      process.exit(0);
    }

    console.log(`üìã ${chunks.length} chunks sans embeddings trouv√©s\n`);

    // Statistiques par cat√©gorie
    const byCategory = new Map<string, number>();
    chunks.forEach(chunk => {
      byCategory.set(chunk.kb_category, (byCategory.get(chunk.kb_category) || 0) + 1);
    });

    console.log('üìä R√©partition par cat√©gorie:');
    Array.from(byCategory.entries())
      .sort((a, b) => b[1] - a[1])
      .forEach(([cat, count]) => {
        console.log(`   - ${cat}: ${count} chunks`);
      });

    if (dryRun) {
      console.log('\n‚úÖ DRY RUN termin√© - Aucun embedding g√©n√©r√©\n');
      process.exit(0);
    }

    // Estimation co√ªt
    const estimatedCost = (chunks.length * 0.00002).toFixed(2); // $0.00002 per 1K tokens (estim√© 1K tokens/chunk)
    const estimatedTime = Math.ceil(chunks.length / 50); // 50 req/s
    console.log(`\nüí∞ Co√ªt estim√©: ~$${estimatedCost}`);
    console.log(`‚è±Ô∏è  Temps estim√©: ~${estimatedTime}s (${Math.ceil(estimatedTime / 60)}min)\n`);

    // Traiter par batch
    const totalBatches = Math.ceil(chunks.length / batchSize);
    let totalSuccess = 0;
    let totalFailed = 0;

    const startTime = Date.now();

    for (let i = 0; i < chunks.length; i += batchSize) {
      const batch = chunks.slice(i, Math.min(i + batchSize, chunks.length));
      const batchIndex = Math.floor(i / batchSize) + 1;

      const { success, failed } = await processBatch(batch, batchIndex, totalBatches);
      totalSuccess += success;
      totalFailed += failed;

      // Afficher progression
      const elapsed = Math.round((Date.now() - startTime) / 1000);
      const processed = i + batch.length;
      const progress = ((processed / chunks.length) * 100).toFixed(1);
      const rate = Math.round(processed / elapsed);

      console.log(`\nüìà Progression: ${processed}/${chunks.length} (${progress}%)`);
      console.log(`   Succ√®s: ${totalSuccess} | √âchecs: ${totalFailed}`);
      console.log(`   Vitesse: ${rate} chunks/s | Temps √©coul√©: ${elapsed}s\n`);
    }

    const totalTime = Math.round((Date.now() - startTime) / 1000);

    // Rapport final
    console.log('\n' + '='.repeat(80));
    console.log('üìä RAPPORT FINAL');
    console.log('='.repeat(80) + '\n');
    console.log(`‚úÖ Succ√®s: ${totalSuccess}/${chunks.length} (${((totalSuccess / chunks.length) * 100).toFixed(1)}%)`);
    console.log(`‚ùå √âchecs: ${totalFailed}/${chunks.length} (${((totalFailed / chunks.length) * 100).toFixed(1)}%)`);
    console.log(`‚è±Ô∏è  Temps total: ${totalTime}s (${Math.ceil(totalTime / 60)}min)`);
    console.log(`‚ö° Vitesse moyenne: ${Math.round(chunks.length / totalTime)} chunks/s\n`);

    // V√©rification finale
    const remainingChunks = await getChunksWithoutEmbeddings(category);
    console.log(`üìä Chunks restants sans embeddings: ${remainingChunks.length}\n`);

    if (remainingChunks.length === 0) {
      console.log('üéâ Tous les embeddings ont √©t√© g√©n√©r√©s avec succ√®s !\n');
    } else {
      console.log('‚ö†Ô∏è  Il reste des chunks sans embeddings. Relancer le script si n√©cessaire.\n');
    }

  } catch (error) {
    console.error('‚ùå Erreur:', error);
    process.exit(1);
  }
}

main();
