/**
 * Script de test pour diagnostiquer le probl√®me de suppression de source web
 *
 * Usage:
 *   npx tsx scripts/test-delete-web-source.ts <sourceId> [--dry-run]
 */

import { db } from '@/lib/db/postgres'
import { deleteWebSourceComplete, getDeletePreview } from '@/lib/web-scraper/delete-service'

async function main() {
  const args = process.argv.slice(2)
  const sourceId = args[0]
  const dryRun = args.includes('--dry-run')

  if (!sourceId) {
    console.error('‚ùå Erreur: sourceId requis')
    console.log('Usage: npx tsx scripts/test-delete-web-source.ts <sourceId> [--dry-run]')
    process.exit(1)
  }

  console.log('üîç Diagnostic suppression source web')
  console.log('=====================================')
  console.log(`Source ID: ${sourceId}`)
  console.log(`Mode: ${dryRun ? 'DRY RUN (aper√ßu seulement)' : 'SUPPRESSION R√âELLE'}`)
  console.log()

  try {
    // √âtape 1: V√©rifier l'existence de la source
    console.log('üìå √âtape 1: V√©rification existence source...')
    const sourceResult = await db.query(
      'SELECT id, name, base_url, category, is_active FROM web_sources WHERE id = $1',
      [sourceId]
    )

    if (sourceResult.rows.length === 0) {
      console.error('‚ùå Source non trouv√©e')
      process.exit(1)
    }

    const source = sourceResult.rows[0]
    console.log('‚úÖ Source trouv√©e:')
    console.log(`   - Nom: ${source.name}`)
    console.log(`   - URL: ${source.base_url}`)
    console.log(`   - Cat√©gorie: ${source.category}`)
    console.log(`   - Active: ${source.is_active}`)
    console.log()

    // √âtape 2: Aper√ßu de la suppression
    console.log('üìä √âtape 2: Aper√ßu des donn√©es √† supprimer...')
    const preview = await getDeletePreview(sourceId)

    console.log(`‚úÖ Donn√©es √† supprimer:`)
    console.log(`   - Documents KB: ${preview.stats.knowledgeBaseDocs}`)
    console.log(`   - Chunks KB: ${preview.stats.knowledgeBaseChunks}`)
    console.log(`   - Pages web: ${preview.stats.webPages}`)
    console.log(`   - Fichiers web: ${preview.stats.webFiles}`)
    console.log(`   - Jobs crawl: ${preview.stats.crawlJobs}`)
    console.log(`   - Logs crawl: ${preview.stats.crawlLogs}`)
    console.log(`   - Fichiers MinIO: ${preview.stats.minioFiles}`)
    console.log(`   - Taille estim√©e: ${preview.estimatedSize}`)
    console.log()

    // √âtape 3: V√©rifier les contraintes FK
    console.log('üîó √âtape 3: V√©rification contraintes FK...')

    // V√©rifier les FK qui pourraient bloquer la suppression
    const fkChecks = [
      {
        table: 'knowledge_base',
        column: "metadata->>'sourceId'",
        label: 'Documents KB',
      },
      {
        table: 'web_pages',
        column: 'web_source_id',
        label: 'Pages web',
      },
      {
        table: 'web_files',
        column: 'web_source_id',
        label: 'Fichiers web',
      },
      {
        table: 'web_crawl_jobs',
        column: 'web_source_id',
        label: 'Jobs crawl',
      },
      {
        table: 'web_crawl_logs',
        column: 'web_source_id',
        label: 'Logs crawl',
      },
      {
        table: 'indexing_jobs',
        column: "source_metadata->>'sourceId'",
        label: 'Jobs indexation',
      },
    ]

    for (const check of fkChecks) {
      const result = await db.query(
        `SELECT COUNT(*) as count FROM ${check.table} WHERE ${check.column} = $1`,
        [sourceId]
      )
      const count = parseInt(result.rows[0].count)
      console.log(`   ${count > 0 ? '‚ö†Ô∏è' : '‚úÖ'} ${check.label}: ${count} enregistrement(s)`)
    }
    console.log()

    // √âtape 4: V√©rifier les jobs en cours
    console.log('‚è≥ √âtape 4: V√©rification jobs en cours...')
    const runningJobsResult = await db.query(
      `SELECT id, job_type, status, started_at
       FROM web_crawl_jobs
       WHERE web_source_id = $1 AND status IN ('queued', 'running')`,
      [sourceId]
    )

    if (runningJobsResult.rows.length > 0) {
      console.log('‚ö†Ô∏è  ATTENTION: Jobs en cours d√©tect√©s:')
      runningJobsResult.rows.forEach(job => {
        console.log(`   - Job ${job.id} (${job.job_type}): ${job.status} depuis ${job.started_at}`)
      })
      console.log('   Recommandation: Attendre la fin des jobs avant suppression')
    } else {
      console.log('‚úÖ Aucun job en cours')
    }
    console.log()

    if (dryRun) {
      console.log('üîç Mode DRY RUN: Aper√ßu seulement, aucune suppression effectu√©e')
      process.exit(0)
    }

    // √âtape 5: Suppression r√©elle
    console.log('üóëÔ∏è  √âtape 5: Suppression en cours...')
    console.log('‚ö†Ô∏è  Cette op√©ration est IRR√âVERSIBLE!')

    const result = await deleteWebSourceComplete(sourceId)

    console.log()
    console.log('üìä R√©sultat de la suppression:')
    console.log(`   - Succ√®s: ${result.success ? '‚úÖ OUI' : '‚ùå NON'}`)
    console.log(`   - Source supprim√©e: ${result.sourceDeleted ? '‚úÖ OUI' : '‚ùå NON'}`)
    console.log()
    console.log('üìà Statistiques:')
    console.log(`   - Documents KB: ${result.stats.knowledgeBaseDocs}`)
    console.log(`   - Chunks KB: ${result.stats.knowledgeBaseChunks}`)
    console.log(`   - Pages web: ${result.stats.webPages}`)
    console.log(`   - Fichiers web: ${result.stats.webFiles}`)
    console.log(`   - Jobs crawl: ${result.stats.crawlJobs}`)
    console.log(`   - Logs crawl: ${result.stats.crawlLogs}`)
    console.log(`   - Fichiers MinIO: ${result.stats.minioFiles}`)

    if (result.errors.length > 0) {
      console.log()
      console.log('‚ö†Ô∏è  Erreurs rencontr√©es:')
      result.errors.forEach(error => {
        console.log(`   - ${error}`)
      })
    }

    console.log()
    if (result.success) {
      console.log('‚úÖ Suppression termin√©e avec succ√®s!')
    } else {
      console.error('‚ùå La suppression a √©chou√©')
      process.exit(1)
    }

  } catch (error) {
    console.error()
    console.error('‚ùå Erreur lors de la suppression:')
    console.error(error)
    process.exit(1)
  } finally {
    await db.end()
  }
}

main()
