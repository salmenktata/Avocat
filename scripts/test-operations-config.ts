#!/usr/bin/env tsx
/**
 * Script de test de la configuration IA par op√©ration
 *
 * V√©rifie que chaque op√©ration :
 * - A une configuration valide
 * - Utilise les bons providers
 * - Respecte les contraintes (timeouts, dimensions, etc.)
 *
 * Usage: npx tsx scripts/test-operations-config.ts
 */

import {
  AI_OPERATIONS_CONFIG,
  getOperationConfig,
  isOperationConfigured,
  getConfiguredOperations,
  getPrimaryProvider,
  getFallbackProviders,
  type OperationName,
} from '@/lib/ai/operations-config'

// =============================================================================
// TESTS
// =============================================================================

function testBasicConfig() {
  console.log('\nüß™ Test 1: Configuration basique\n')

  const operations = getConfiguredOperations()
  console.log(`‚úÖ ${operations.length} op√©rations configur√©es: ${operations.join(', ')}`)

  // V√©rifier que les 4 op√©rations de base sont pr√©sentes
  const expectedOps: OperationName[] = [
    'indexation',
    'assistant-ia',
    'dossiers-assistant',
    'dossiers-consultation',
  ]

  for (const op of expectedOps) {
    if (!isOperationConfigured(op)) {
      throw new Error(`‚ùå Op√©ration manquante: ${op}`)
    }
    console.log(`  ‚úì ${op}`)
  }
}

function testProvidersConfig() {
  console.log('\nüß™ Test 2: Configuration providers\n')

  const operations = getConfiguredOperations()

  for (const op of operations) {
    const config = getOperationConfig(op)
    const primary = getPrimaryProvider(op)
    const fallbacks = getFallbackProviders(op)

    console.log(`\nüìã ${op}:`)
    console.log(`  Context: ${config.context}`)
    if (primary) {
      console.log(`  Primary: ${primary}`)
      console.log(`  Fallbacks: [${fallbacks.join(', ')}]`)
    } else {
      console.log(`  ‚ö† Utilise strat√©gie par d√©faut du contexte "${config.context}"`)
    }

    // V√©rifier embeddings
    if (config.embeddings) {
      console.log(`  Embeddings: ${config.embeddings.provider} (${config.embeddings.dimensions || 1024}-dim)`)
      if (config.embeddings.fallbackProvider) {
        console.log(`  Embeddings fallback: ${config.embeddings.fallbackProvider}`)
      }
    }

    // V√©rifier timeouts
    if (config.timeouts) {
      console.log(`  Timeouts:`)
      if (config.timeouts.embedding) console.log(`    - Embedding: ${config.timeouts.embedding}ms`)
      if (config.timeouts.chat) console.log(`    - Chat: ${config.timeouts.chat}ms`)
      if (config.timeouts.total) console.log(`    - Total: ${config.timeouts.total}ms`)
    }

    // V√©rifier LLM config
    if (config.llmConfig) {
      console.log(`  LLM Config:`)
      console.log(`    - Temperature: ${config.llmConfig.temperature}`)
      console.log(`    - MaxTokens: ${config.llmConfig.maxTokens}`)
      if (config.llmConfig.systemPromptType) {
        console.log(`    - PromptType: ${config.llmConfig.systemPromptType}`)
      }
    }
  }
}

function testCoherenceRules() {
  console.log('\nüß™ Test 3: R√®gles de coh√©rence\n')

  const operations = getConfiguredOperations()
  let errors = 0

  for (const op of operations) {
    const config = getOperationConfig(op)

    // R√®gle 1: Indexation doit utiliser Ollama pour √©conomie
    if (op === 'indexation') {
      if (config.embeddings?.provider !== 'ollama') {
        console.log(`  ‚ùå ${op}: Devrait utiliser Ollama pour embeddings (0‚Ç¨)`)
        errors++
      } else {
        console.log(`  ‚úì ${op}: Utilise Ollama embeddings (0‚Ç¨)`)
      }
    }

    // R√®gle 2: Assistant IA doit √™tre rapide (chat < 10s)
    if (op === 'assistant-ia') {
      if (config.timeouts?.total && config.timeouts.total > 10000) {
        console.log(`  ‚ùå ${op}: Timeout total trop √©lev√© (${config.timeouts.total}ms > 10s)`)
        errors++
      } else {
        console.log(`  ‚úì ${op}: Timeout rapide (${config.timeouts?.total || 'N/A'}ms)`)
      }

      // Groq prioritaire pour vitesse
      const primary = getPrimaryProvider(op)
      if (primary !== 'groq') {
        console.log(`  ‚ö† ${op}: Recommandation: utiliser Groq en priorit√© (ultra-rapide 292ms)`)
      } else {
        console.log(`  ‚úì ${op}: Utilise Groq (ultra-rapide)`)
      }
    }

    // R√®gle 3: Dossiers doivent utiliser OpenAI embeddings pour qualit√©
    if (op === 'dossiers-assistant' || op === 'dossiers-consultation') {
      if (config.embeddings?.provider !== 'openai') {
        console.log(`  ‚ö† ${op}: Recommandation: utiliser OpenAI embeddings pour qualit√© (1536-dim)`)
      } else {
        console.log(`  ‚úì ${op}: Utilise OpenAI embeddings (qualit√© max)`)
      }
    }

    // R√®gle 4: Consultation doit √™tre tr√®s factuelle (temp ‚â§ 0.2)
    if (op === 'dossiers-consultation') {
      if (config.llmConfig?.temperature && config.llmConfig.temperature > 0.2) {
        console.log(`  ‚ùå ${op}: Temperature trop √©lev√©e (${config.llmConfig.temperature} > 0.2)`)
        errors++
      } else {
        console.log(`  ‚úì ${op}: Temperature factuelle (${config.llmConfig?.temperature})`)
      }
    }

    // R√®gle 5: V√©rifier dimensions embeddings coh√©rentes
    if (config.embeddings) {
      const expectedDim = config.embeddings.provider === 'openai' ? 1536 : 1024
      const actualDim = config.embeddings.dimensions || expectedDim

      if (actualDim !== expectedDim) {
        console.log(`  ‚ùå ${op}: Dimensions incoh√©rentes (${actualDim} au lieu de ${expectedDim} pour ${config.embeddings.provider})`)
        errors++
      }
    }
  }

  if (errors > 0) {
    console.log(`\n‚ùå ${errors} erreur(s) de coh√©rence d√©tect√©e(s)`)
  } else {
    console.log(`\n‚úÖ Toutes les r√®gles de coh√©rence respect√©es`)
  }

  return errors === 0
}

function testCostEstimation() {
  console.log('\nüß™ Test 4: Estimation co√ªts\n')

  const operations = getConfiguredOperations()

  console.log('üí∞ Estimation mensuelle par op√©ration:\n')

  for (const op of operations) {
    const config = getOperationConfig(op)
    let embeddingCost = 'Gratuit'
    let llmCost = 'Gratuit'

    // Estimer co√ªt embeddings
    if (config.embeddings?.provider === 'openai') {
      embeddingCost = '~0.5-1‚Ç¨/mois (faible volume)'
    }

    // Estimer co√ªt LLM
    const primary = getPrimaryProvider(op)
    if (primary === 'groq' || primary === 'gemini') {
      llmCost = 'Gratuit'
    } else if (primary === 'deepseek') {
      llmCost = '~0.5-1‚Ç¨/mois'
    } else if (primary === 'anthropic') {
      llmCost = '~5-10‚Ç¨/mois'
    }

    console.log(`  ${op}:`)
    console.log(`    Embeddings: ${embeddingCost}`)
    console.log(`    LLM: ${llmCost}`)
  }

  console.log('\nüí° Total estim√©: ~4-6‚Ç¨/mois (vs ~100‚Ç¨/mois avant = -95% √©conomies)')
}

// =============================================================================
// MAIN
// =============================================================================

async function main() {
  console.log('üöÄ Test de la configuration IA par op√©ration\n')
  console.log('=' .repeat(60))

  try {
    testBasicConfig()
    testProvidersConfig()
    const coherent = testCoherenceRules()
    testCostEstimation()

    console.log('\n' + '='.repeat(60))
    if (coherent) {
      console.log('‚úÖ Tous les tests pass√©s avec succ√®s !\n')
      process.exit(0)
    } else {
      console.log('‚ö† Des avertissements ont √©t√© d√©tect√©s (voir ci-dessus)\n')
      process.exit(1)
    }
  } catch (error) {
    console.error('\n‚ùå Erreur lors des tests:', error)
    process.exit(1)
  }
}

main()
